# tta/agents/narrative_generator.py
"""
Narrative Generator Agent (NGA) for the Therapeutic Text Adventure (TTA).

The NGA is responsible for generating the narrative text that the player
experiences, including:

*   Location descriptions
*   Character dialogue
*   Event descriptions
*   Responses to player actions

The NGA uses:

*   **LangChain:** For prompt templates and LLM interaction.
*   **Qwen2.5:** The Large Language Model (LLM) for text generation.
*   **Neo4j (via tools):**  For retrieving information from the knowledge graph
    (location details, character profiles, lore, etc.).
*   **CoRAG:** To iteratively refine its output by retrieving additional
    information as needed.
*   **Pydantic:**  For defining output schema.

Key Responsibilities:

*   **Generate Descriptive Text:** Create vivid and engaging descriptions of
    the game world, including locations, objects, and characters.
*   **Generate Dialogue:** Create realistic and contextually appropriate
    dialogue for NPCs, taking into account their personality, relationships,
    and the current situation.
*   **Respond to Player Actions:**  Generate text that reflects the
    consequences of the player's actions and choices.
*   **Maintain Narrative Consistency:** Ensure that the generated text is
    consistent with the established lore, character backstories, and previous
    events.
*   **Integrate Therapeutic Concepts:** Subtly weave therapeutic concepts
    (e.g., resilience, self-compassion) into the narrative.
*   **CoRAG:** Use Chain-of-Retrieval Augmented Generation to iteratively
    retrieve information and refine its output.

"""

import json
from typing import Dict, List, Optional

import settings
from langchain.prompts import PromptTemplate
from langchain.schema.output_parser import StrOutputParser
from langchain_openai import ChatOpenAI
from schema import (
    AgentState,
    GetCharacterProfileInput,
    GetCharacterProfileOutput,
    QueryKnowledgeGraphInput,
    QueryKnowledgeGraphOutput,
)  # Import relevant schemas
from utils.neo4j_utils import execute_query, get_node_by_id

# --- LLM Setup (LM Studio) ---
llm = ChatOpenAI(
    openai_api_base=settings.LLM_API_BASE,
    api_key=settings.LLM_API_KEY,
    model=settings.LLM_MODEL_NAME,
    temperature=settings.DEFAULT_TEMPERATURE,  # Add temperature
)

# --- Prompt Template (Simplified Example) ---
# This is a basic example; a real NGA would have a much more complex prompt.
NGA_PROMPT_TEMPLATE = """
You are the Narrative Generator Agent (NGA) for a text adventure game.

Current Location: {current_location}
Nearby Characters: {nearby_characters}
Player Input: {player_input}

Your task is to generate a response to the player's action,
considering the current game state and character information.
Maintain a consistent and engaging narrative style.

Output Format:
{{
  "response": "...",  // The generated text
  "action": "..."     // Optional: A brief description of any action taken
}}
"""

prompt_template = PromptTemplate.from_template(NGA_PROMPT_TEMPLATE)

# --- Output Parser ---
output_parser = StrOutputParser()

# --- LangChain Chain (Simplified) ---
nga_chain = prompt_template | llm | output_parser


# --- CoRAG (Conceptual - Placeholder for LangGraph integration) ---
def perform_corag(initial_response: str, state: AgentState) -> str:
    """
    Performs a simplified version of CoRAG to enhance the NGA's response.
    This is a placeholder for a more complete LangGraph-based implementation.

    Args:
        initial_response: The initial response generated by the NGA.
        state: The current AgentState.

    Returns:
        A refined response string.
    """
    refined_response = initial_response

    # Example: Get more details about the current location.
    location_id = state.game_state.current_location_id
    location_details = get_node_by_id(
        "Location", location_id
    )  # Using the utility function.

    if location_details:
        refined_response += (
            f"\n\nYou are in {location_details.get('name', 'an unknown location')}. "
        )
        description = location_details.get("description")
        if description:
            refined_response += description

    # Add more CoRAG steps as needed (e.g., get character details, check lore).
    return refined_response


# --- Main NGA Logic ---


def generate_narrative(state: AgentState) -> Dict[str, str]:
    """
    Generates narrative text based on the current game state.

    Args:
        state: The current AgentState.

    Returns:
        A dictionary containing the generated text and any actions taken.
    """
    # --- 1. Prepare Prompt Input ---
    prompt_input = {
        "current_location": state.game_state.current_location_id,  #  Get location ID
        "nearby_characters": ", ".join(
            state.game_state.nearby_characters
        ),  # Format as string
        "player_input": state.player_input or "",  # Handle potential None value
        "metaconcepts": state.metaconcepts,  # Include metaconcepts
    }

    # --- 2. Generate Initial Response ---
    response_str = nga_chain.invoke(prompt_input)

    try:
        response_dict = json.loads(response_str)
    except json.JSONDecodeError:
        print(f"ERROR: NGA returned invalid JSON: {response_str}")
        return {
            "response": "I'm having trouble understanding the situation. Please try again.",
            "action": None,
        }

    # --- 3. Perform CoRAG (if needed) ---
    refined_response = perform_corag(
        response_dict.get("response", ""), state
    )  # Use .get()
    response_dict["response"] = refined_response

    # --- 4. Update and Return ---
    return response_dict


# --- Example Usage (within a LangGraph workflow) ---
# This would be part of a larger LangGraph setup, not a standalone function.
# def nga_node(state: AgentState) -> AgentState:
#     """
#     LangGraph node for the NGA.  This function wraps the core NGA logic
#     so it can be used within a LangGraph workflow.
#     """
#     response = generate_narrative(state)
#     new_state = state.copy()  # Create a copy to modify
#     new_state.response = response["response"]
#     # Update other parts of the state as needed (e.g., conversation history)
#     return new_state
